<!DOCTYPE html>

<html lang="en" dir="ltr">

<head>
  <meta charset="utf-8">
  <title>BHUVAN AI - Voice Assistant</title>
  <link rel="stylesheet" href="style.css">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- Google Fonts Link For Icons -->
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@48,400,0,0" />
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@48,400,1,0" />
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" rel="stylesheet">
    
  <script src="script.js" defer></script>
  <script src="https://kit.fontawesome.com/beac85e0c4.js" crossorigin="anonymous"></script>
  <style>
    body {
      background-image: url('Revolutionizing.png');
      background-size: cover;
      background-repeat: no-repeat;
    }
  </style>


  
</head>
  

<body>
  <nav class="navbar navbar-expand-lg navbar-light bg-light">
    <a class="navbar-brand" href="#">BHUVAN.AI</a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
    <div class="collapse navbar-collapse" id="navbarNav">
      <ul class="navbar-nav">
        <li class="nav-item active">
          <a class="nav-link" href="#">Home <span class="sr-only">(current)</span></a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="mailto:yash.gupta.ug23@nsut.ac.in">Contact us</a>
        </li>

      </ul>
    </div>
  </nav>

  <button class="chatbot-toggler">
    <span class="material-symbols-rounded">mode_comment</span>
    <span class="material-symbols-outlined">close</span>
  </button>
  <div class="chatbot">
    <header>
      <h2>Bhuvan.Ai</h2>
      <span class="close-btn material-symbols-outlined">close</span>
    </header>
    <ul class="chatbox">
      <li class="chat incoming">
        <span class="material-symbols-outlined">smart_toy</span>
        <p>Hi there üëã<br>How can I help you today?</p>
      </li>
    </ul>


    <div class="chat-input">
      <!-- Add an ID to the textarea -->
      <textarea id="chatTextarea" placeholder="Enter a message..." spellcheck="false" required></textarea>
      <span id="send-btn" class="material-symbols-rounded">send</span>
       <button id="toggleRecording">üéôÔ∏è</button>
    </div>

  <!--  <script>
      function startDictation() {
        var recognition = new webkitSpeechRecognition();
        recognition.onresult = function(event) {
          console.log(event.results[0][0].transcript);
        }
        recognition.start();
      }
    </script>-->


  <style>
    #toggleRecording{
      border-radius: 50%;
      background-color: #0CFBFF;
      height: 50px;
      width: 60px;
    } 
  </style>

    <script>
      function updatePlaceholderText(text) {
        const chatInput = document.getElementById('chatTextarea');
        chatInput.placeholder = text;
    }
        document.addEventListener('DOMContentLoaded', () => {
            let mediaRecorder;
            let audioChunks = [];
            let isRecording = false;

            const toggleRecordingButton = document.getElementById('toggleRecording');

            toggleRecordingButton.addEventListener('click', toggleRecording);

            async function toggleRecording() {
                if (!isRecording) {
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

                    mediaRecorder = new MediaRecorder(stream);
                    audioChunks = []; // Clear the array before starting a new recording

                    mediaRecorder.ondataavailable = event => {
                        if (event.data.size > 0) {
                            audioChunks.push(event.data);
                        }
                    };

                    mediaRecorder.onstop = async () => {
                        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' }); // You can change 'audio/wav' to 'audio/mp3' if needed
                        await sendAudioToWhisperAPI(audioBlob);
                        // Send the recorded audio to the FastAPI endpoint
                        //await sendAudioToEndpoint(audioBlob);

                        // Clear recorded audio and enable button for the next recording
                        audioChunks = [];
                        isRecording = false;
                        toggleRecordingButton.textContent = 'üéôÔ∏è';
                    };

                    mediaRecorder.start();
                    isRecording = true;
                    toggleRecordingButton.textContent = 'üî¥';
                } else {
                    mediaRecorder.stop();
                }
            }

            /*async function sendAudioToEndpoint(audioBlob) {
                // Adjust the URL to your FastAPI endpoint
                const apiUrl = 'https://your-fastapi-endpoint.com/upload-audio';

                try {
                    const response = await fetch(apiUrl, {
                        method: 'POST',
                        body: audioBlob,
                        headers: {
                            'Content-Type': 'audio/wav', // Set the appropriate content type
                        },
                    });

                    if (!response.ok) {
                        throw new Error(`HTTP error! Status: ${response.status}`);
                    }

                    const responseData = await response.json();
                    console.log('Response from FastAPI:', responseData);
                } catch (error) {
                    console.error('Error sending audio to FastAPI:', error);
                }
            }*/

                async function sendAudioToWhisperAPI(audioBlob) {
                    const apiKey = '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';  // Replace with your Whisper API key
                    const apiUrl = 'https://api.openai.com/v1/whisper/asr';
            
                    try {
                        const response = await fetch(apiUrl, {
                            method: 'POST',
                            body: audioBlob,
                            headers: {
                                'Authorization': `Bearer ${apiKey}`,
                                'Content-Type': 'audio/wav',
                            },
                        });
            
                        if (!response.ok) {
                            throw new Error(`HTTP error! Status: ${response.status}`);
                        }
            
                        const responseData = await response.json();
                        const transcribedText = responseData['text'];
                        console.log('Transcribed Text:', transcribedText);
                        updatePlaceholderText(transcribedText);

                        // Now you can use the transcribed text as needed (store in a variable, display, etc.)
                    } catch (error) {
                        console.error('Error sending audio to Whisper API:', error);
                    }
                }    
        });
    </script>





</body>

</html>